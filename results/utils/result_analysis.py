import os
import json
import pandas as pd


##################################################
################## LOAD DATA #####################
##################################################

"""
This script reads in all predictions, and creates a big dataframe. From that it creates violin plots for each 
language pair, and model. 
The results dictionary should look like this:

results/
â”œâ”€â”€ TM/
â”‚   â””â”€â”€ predictions.jsonl
â”œâ”€â”€ TM_2bit/
â”‚   â””â”€â”€ predictions.jsonl
â”œâ”€â”€ TM_3bit/
â”‚   â””â”€â”€ predictions.jsonl
...
â”œâ”€â”€ TM_8bit/
â”‚   â””â”€â”€ predictions.jsonl

Example structure of the combined DataFrame (df):
â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    â”‚ id                                                           â”‚ langpair â”‚ src_lang â”‚ tgt_lang â”‚ src                                                          â”‚ ref                                      â”‚ pred                                     â”‚ difficulty_score â”‚ difficulty_bin                              â”‚ meta_domain â”‚ meta_segment_id â”‚ meta_is_bad_source â”‚ meta_original_target                      â”‚ meta_difficulty_score â”‚ metrics_chrf â”‚ metrics_comet_seg â”‚ binning           â”‚ model â”‚ bin_lower â”‚ difficulty_label â”‚
â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0  â”‚ test-en-social_112289379466442912:654:en-de                 â”‚ en-de  â”‚ en       â”‚ de       â”‚ Does this make sense? Would this be useful?                     â”‚ Macht das Sinn? WÃ¤re das hilfreich?      â”‚ Macht das Sinn? WÃ¤re das nÃ¼tzlich?      â”‚ 0.978634          â”‚ (0.9307763735422399-0.9958426710938243]     â”‚ social     â”‚ 654               â”‚ False             â”‚ Macht das Sinn? WÃ¤re das hilfreich?   â”‚ 0.978634                  â”‚ 70.314645     â”‚ 0.976394          â”‚ quantile_balanced â”‚ TM   â”‚ 0.930776  â”‚ Hard             â”‚
â”‚ 1  â”‚ test-en-social_112112980319428992:418:en-zh                 â”‚ en-zh  â”‚ en       â”‚ zh       â”‚ I'm splurging on a new set of frames, these re...              â”‚ æˆ‘èŠ±å¤§ä»·é’±ä¹°äº†ä¸€å‰¯æ–°é•œæ¡†ï¼Œè¿™å‰¯çº¢è‰²çš„æˆ‘å¾ˆå–œæ¬¢ã€‚ â”‚ æˆ‘å‡†å¤‡ä¹°ä¸€å‰¯æ–°çœ¼é•œï¼Œè¿™å‰¯çº¢è‰²çš„æˆ‘ç‰¹åˆ«å–œæ¬¢ã€‚        â”‚ 0.889706          â”‚ (0.8641313217143293-0.9307763735422399]     â”‚ social     â”‚ 418               â”‚ False             â”‚ æˆ‘èŠ±é«˜ä»·ä¹°äº†ä¸€å‰¯æ–°é•œæ¡†ï¼Œæ˜¯æˆ‘éå¸¸å–œæ¬¢çš„çº¢è‰².  â”‚ 0.889706                  â”‚ 33.162672     â”‚ 0.881692          â”‚ quantile_balanced â”‚ TM   â”‚ 0.864131  â”‚ Medium           â”‚
â”‚ 2  â”‚ test-en-social_112122127346453600:459:en-nl                 â”‚ en-nl  â”‚ en       â”‚ nl       â”‚ Chapter five is a long one, but so fucking ang...              â”‚ Hoofdstuk vijf wordt lang, maar echt vres â”‚ Hoofdstuk vijf is lang, maar zo ontzetteâ”‚ 0.886705          â”‚ (0.8641313217143293-0.9307763735422399]     â”‚ social     â”‚ 459               â”‚ False             â”‚ Hoofstuk vijf wordt een lange, maar ecâ”‚ 0.886705                  â”‚ 40.075556     â”‚ 0.723553          â”‚ quantile_balanced â”‚ TM   â”‚ 0.864131  â”‚ Medium           â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

"""

# Path to your results directory
base_dir = "../../results"

# Helper: flatten nested dictionaries (1-level deep)
def flatten_dict(d, parent_key='', sep='_'):
    items = []
    for k, v in d.items():
        new_key = f"{parent_key}{sep}{k}" if parent_key else k
        if isinstance(v, dict):
            items.extend(flatten_dict(v, new_key, sep=sep).items())
        else:
            items.append((new_key, v))
    return dict(items)

# Collect all prediction data
all_data = []

for model_dir in os.listdir(base_dir):
    model_path = os.path.join(base_dir, model_dir)
    predictions_path = os.path.join(model_path, "predictions.jsonl")
    
    if os.path.isfile(predictions_path):
        with open(predictions_path, "r", encoding="utf-8") as f:
            for line in f:
                entry = json.loads(line.strip())
                entry_flat = flatten_dict(entry)   # flatten nested dicts
                entry_flat["model"] = model_dir    # add model identifier
                all_data.append(entry_flat)

# Convert to DataFrame
df = pd.DataFrame(all_data)

print(f"âœ… Loaded {len(df)} entries from {df['model'].nunique()} models.")


###################################################
############### PRE-PROCESS DATA ##################
###################################################

import re 

# --- Filter out entries without valid difficulty bins ---
df = df[df["difficulty_bin"].notna()]
df = df[df["difficulty_bin"] != ""]  # remove empty strings
df = df[df["difficulty_bin"] != "UNBINNED"]

# --- Sort bins numerically ---
# Extract lower bound from strings like "(0.9307-0.9958]"
def get_lower_bound(bin_str):
    match = re.search(r"([\d.]+)-", bin_str)
    return float(match.group(1)) if match else float("inf")

df["bin_lower"] = df["difficulty_bin"].apply(get_lower_bound)

# Sort unique bins and assign easy â†’ hard labels
unique_bins = sorted(df["difficulty_bin"].unique(), key=lambda b: get_lower_bound(b))
labels = ["Easy", "Medium", "Hard", "Very Hard"][:len(unique_bins)]

# Map old bin names to difficulty labels
bin_map = dict(zip(unique_bins, labels))
df["difficulty_label"] = df["difficulty_bin"].map(bin_map)

print("ğŸ“Š Difficulty bin mapping:")
for old, new in bin_map.items():
    print(f"  {old} â†’ {new}")

###############################################
################## CREATE PLOTS ###############
###############################################

import seaborn as sns
import matplotlib.pyplot as plt

# Ensure difficulty order
difficulty_order = ["Easy", "Medium", "Hard"]

# Create a FacetGrid: one column per language pair, one row per model
g = sns.FacetGrid(
    df,
    row="model",
    col="langpair",
    sharey=True,
    margin_titles=True,
    despine=False,
    height=3.5,
    aspect=1.2
)

# Draw the violin plots in each facet
g.map_dataframe(
    sns.violinplot,
    x="difficulty_label",
    y="metrics_comet_seg",
    order=difficulty_order,
    inner="box",
    cut=0,
    scale="width",
    palette="Blues"
)

# Adjust layout and titles
g.set_axis_labels("Difficulty", "COMET Segment Score")
g.set_titles(row_template="{row_name}", col_template="{col_name}")
for ax in g.axes.flatten():
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right")

plt.tight_layout()
plt.subplots_adjust(top=0.92)
g.fig.suptitle("COMET Score Distributions by Difficulty, Model, and Language Pair", fontsize=16)

plt.savefig("plots_violin/all_models_comparison_grid.png", dpi=250)
plt.show()
